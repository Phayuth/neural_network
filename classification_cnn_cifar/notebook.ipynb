{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cff3c525-17f8-459a-8e0e-b4646dcb2f4b",
   "metadata": {},
   "source": [
    "https://blog.paperspace.com/writing-cnns-from-scratch-in-pytorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6934e746-95f6-4235-83c1-db4d64850adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/airlab/anaconda3/envs/yuth-mldl/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ec4641c-14ef-4c08-93fa-b1960e07b6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_classes = 10\n",
    "learning_rate = 0.001\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8eb3aa-1cde-4390-8b4a-97dd4f3e3fbb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Create Transfomation for Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75469216-4046-4a79-8ccb-f1731cf0b116",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_transforms = transforms.Compose([transforms.Resize((32,32)),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                                                          std=[0.2023, 0.1994, 0.2010])\n",
    "                                     ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d91d53-8597-4212-a78f-3ebc24ffe97b",
   "metadata": {},
   "source": [
    "# Load Dataset from library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64df9a5b-8ddf-458e-8b93-e03978d84757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [01:16<00:00, 2232968.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root = './data',\n",
    "                                             train = True,\n",
    "                                             transform = all_transforms,\n",
    "                                             download = True)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root = './data',\n",
    "                                            train = False,\n",
    "                                            transform = all_transforms,\n",
    "                                            download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58fe985-771c-4e2c-a9cc-034e522d18ed",
   "metadata": {},
   "source": [
    "# Load Dataset into Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc89708f-a4e1-489e-b9f3-33c14a38245a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a665a946-3f7f-4aca-9efd-b7d389a64a2b",
   "metadata": {},
   "source": [
    "# View and Verify Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "235eba1f-c72b-467c-8e89-5bfc3ae3d3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16575/2520509552.py:8: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matricesor `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484809662/work/aten/src/ATen/native/TensorShape.cpp:2981.)\n",
      "  plt.imshow(img_single.T)\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64])\n",
      "torch.Size([3, 32, 32])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for img, targ in train_loader:\n",
    "    print(img.size())\n",
    "    print(targ.size())\n",
    "    img_single = img[0]\n",
    "    print(img_single.size())\n",
    "    plt.imshow(img_single.T)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dfe498-a454-4ee9-94e2-cadafb17613f",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0059e890-ab07-4f40-8d5d-a3de5a4cd82d",
   "metadata": {},
   "source": [
    "![](https://blog.paperspace.com/content/images/size/w1000/2021/05/image-32.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8622a3b9-ca0f-46a9-84fe-b8daa462853e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNeuralNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ConvNeuralNet, self).__init__()\n",
    "        self.conv_layer1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3)\n",
    "        self.conv_layer2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3)\n",
    "        self.max_pool1 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        \n",
    "        self.conv_layer3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "        self.conv_layer4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3)\n",
    "        self.max_pool2 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(1600, 128)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv_layer1(x)\n",
    "        out = self.conv_layer2(out)\n",
    "        out = self.max_pool1(out)\n",
    "        \n",
    "        out = self.conv_layer3(out)\n",
    "        out = self.conv_layer4(out)\n",
    "        out = self.max_pool2(out)\n",
    "                \n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        \n",
    "        out = self.fc1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1279293b-39eb-4ec7-9934-dbf5c7e82ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNeuralNet(\n",
      "  (conv_layer1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv_layer2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (max_pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv_layer3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv_layer4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (max_pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=1600, out_features=128, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = ConvNeuralNet(num_classes).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b25061-0704-4498-8f1b-16badeb666c1",
   "metadata": {},
   "source": [
    "# Create Loss and Optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40cae969-da69-4f39-a71b-8461becd474d",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.005, momentum = 0.9)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ad6147-72ca-44d8-9f37-422cc651af03",
   "metadata": {},
   "source": [
    "# Training Montage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "300bccd2-e9a0-4cc5-967a-1e3328dbb1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.4660\n",
      "Epoch [2/20], Loss: 1.2265\n",
      "Epoch [3/20], Loss: 1.2492\n",
      "Epoch [4/20], Loss: 1.3535\n",
      "Epoch [5/20], Loss: 1.6909\n",
      "Epoch [6/20], Loss: 1.3219\n",
      "Epoch [7/20], Loss: 0.9838\n",
      "Epoch [8/20], Loss: 1.0381\n",
      "Epoch [9/20], Loss: 1.0829\n",
      "Epoch [10/20], Loss: 0.8442\n",
      "Epoch [11/20], Loss: 1.2387\n",
      "Epoch [12/20], Loss: 1.4314\n",
      "Epoch [13/20], Loss: 1.0455\n",
      "Epoch [14/20], Loss: 1.0568\n",
      "Epoch [15/20], Loss: 0.3705\n",
      "Epoch [16/20], Loss: 0.5460\n",
      "Epoch [17/20], Loss: 0.4743\n",
      "Epoch [18/20], Loss: 1.0389\n",
      "Epoch [19/20], Loss: 0.5670\n",
      "Epoch [20/20], Loss: 0.6282\n"
     ]
    }
   ],
   "source": [
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # Move tensors to the configured device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0494a3a0-ab04-4efb-879d-99887092f325",
   "metadata": {},
   "source": [
    "# Testing Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3d7ff37-3159-4109-9990-ec8194a0db1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 50000 train images: 81.854 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print('Accuracy of the network on the {} train images: {} %'.format(50000, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e4d5584-c88c-4c2f-aec4-ffb5a5138e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab83fe6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yuth-mldl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:26:10) \n[GCC 11.2.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "ea1eab7b55522cfd78d4c86d123511d3b1ac86a861556ba9bf273c459b4d6b8e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
